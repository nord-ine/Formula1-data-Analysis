{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplissage du dataset des pit-stops\n",
    "\n",
    "Le dataset que nous utilisons est incomplet : en effet, il ne propose les informations de pit-stop qu'à partir de la 841e course, alors que les données des temps au tour sont disponibles pour beaucoup plus de courses. Nous souhaitons remplir ce dataset.\n",
    "\n",
    "On remarque qu'un pit-stop est symbolisé sur le graphique des temps au tour par un pic brusque entre deux tours rapides. Il est donc possible d'utiliser un algorithme d'apprentissage supervisé pour trouver les pit-stops à chaque course.\n",
    "\n",
    "![herothisaustria.jpg](attachment:herothisaustria.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import scikitplot as skplt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitStops = pd.read_csv(\"datasets/pit_stops.csv\")\n",
    "lapTimes = pd.read_csv(\"datasets/lap_times.csv\")\n",
    "races = pd.read_csv(\"datasets/races.csv\",index_col=0)\n",
    "races = races.drop(columns=['url','time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des sets : \n",
    "on va avoir un training set d'environ beaucoup d'exemples. On peut essayer d'appliquer la technique de cross-validation pour entraîner le modèle. <br>\n",
    "Quelles sont les features ? \n",
    "<ul>\n",
    "    <li>driverId</li>\n",
    "    <li>circuitId</li>\n",
    "    <li>lap</li>\n",
    "    <li>milliseconds</li>\n",
    "</ul>\n",
    "Le label est un vecteur y de taille $m = nbLaps$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_pit.csv a été généré par moi, il contient les courses dont on connaît les informations de pit\n",
    "my_dataset = pd.read_csv('dataset_pit.csv', index_col=0)\n",
    "#En raison d'incidents pouvant survenir en début de course, on a beaucoup de pits dans les premiers tours\n",
    "#Ils créent un bruit inutile et peuvent rendre la prédiction moins précise\n",
    "#On retire donc les informations de tour avant le 5e tour.\n",
    "my_dataset = my_dataset[my_dataset['lap'] > 5]\n",
    "\n",
    "#On va créer une colonne contenant le temps du tour précédent\n",
    "my_dataset['previousLap'] = np.zeros(my_dataset.shape[0])\n",
    "\n",
    "#Pour ce faire, on effectue une translation du dataset dans une copie.\n",
    "my_dataset_trans = my_dataset.shift(1)\n",
    "\n",
    "#On duplique la première ligne pour qu'elle ne soit pas vide\n",
    "my_dataset_trans.iloc[0] = my_dataset.iloc[0]\n",
    "\n",
    "#On associe les deux champs. On rajoute raceId et driverId pour que le tour précédent corresponde bien au bon pilote.\n",
    "my_dataset['previousLap'] = my_dataset_trans['milliseconds']\n",
    "my_dataset['previousLapRaceId'] = my_dataset_trans['raceId']\n",
    "my_dataset['previousLapDriverId'] = my_dataset_trans['driverId']\n",
    "my_dataset['previousLapPit'] = my_dataset_trans['pit']\n",
    "\n",
    "#Le rapport du temps au tour actuel et du temps au tour précédent.\n",
    "my_dataset['previousLapDelta'] = np.where((my_dataset['raceId'] == my_dataset['previousLapRaceId']) & (my_dataset['driverId'] == my_dataset['previousLapDriverId']) & my_dataset['previousLapPit'] != 1, my_dataset['milliseconds']/my_dataset['previousLap'], 1)\n",
    "\n",
    "#On répète exactement la même opération pour le tour suivant\n",
    "my_dataset_fwd = my_dataset.shift(-1)\n",
    "my_dataset_fwd.loc[my_dataset_fwd.shape[0]] =  my_dataset.loc[my_dataset.shape[0]]\n",
    "my_dataset['nextLap'] = my_dataset_fwd['milliseconds']\n",
    "my_dataset['nextLapRaceId'] = my_dataset_fwd['raceId']\n",
    "my_dataset['nextLapDriverId'] = my_dataset_fwd['driverId']\n",
    "my_dataset['nextLapPit'] = my_dataset_fwd['pit']\n",
    "my_dataset['nextLapDelta'] = np.where((my_dataset['raceId'] == my_dataset['nextLapRaceId']) & (my_dataset['driverId'] == my_dataset['nextLapDriverId']) & my_dataset['nextLapPit'] != 1, (my_dataset['milliseconds']/my_dataset['nextLap']), 1)\n",
    "\n",
    "#lapDelta correspond à la différence du tour actuel par rapport au précédent ET au suivant\n",
    "my_dataset['lapDelta'] = (my_dataset['previousLapDelta']+my_dataset['nextLapDelta'])/2\n",
    "\n",
    "#On accentue les résultats : si lapDelta ~ 1 alors on affecte une valeur 1-exp(1-1) ~ 0 \n",
    "#                            si lapDelta >> 1 alors on affecte une valeur 10*(1-exp(1-1,5)) >~ 1\n",
    "my_dataset['lapDelta'] = my_dataset['lapDelta'].apply(lambda x: 10.0*(1-np.exp(1-x)))\n",
    "\n",
    "#On centre les résultats (attention : l'algorithme fonctionne mieux si on ne le fait pas)\n",
    "# my_dataset['lapDelta'] = (my_dataset['lapDelta']-my_dataset['lapDelta'].mean())/my_dataset['lapDelta'].std()\n",
    "\n",
    "#Si la valeur est plus petite que 0,05 on affecte 0, sinon on multiplie par 10\n",
    "#\"Feature engineering at its finest\"\n",
    "my_dataset['lapDelta'] = np.where((np.abs(my_dataset['lapDelta']) < 0.05) | (my_dataset['pit'] == 0),0,10*my_dataset['lapDelta'])\n",
    "\n",
    "#On retire les colonnes dont on n'a pas besoin\n",
    "my_dataset = my_dataset.drop(['previousLap','previousLapRaceId','previousLapDriverId','nextLap','nextLapRaceId','nextLapDriverId'],axis=1)\n",
    "\n",
    "#On retire les 50 valeurs les plus grandes qui peuvent empêcher un apprentissage de qualité ta3 Montessori\n",
    "for i in range(1,50):\n",
    "    my_dataset = my_dataset.drop(my_dataset['previousLapDelta'].idxmax())\n",
    "    my_dataset = my_dataset.drop(my_dataset['nextLapDelta'].idxmax())\n",
    "\n",
    "#On affiche le dataset préparé.    \n",
    "display(my_dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut transformer le problème en un problème de régression logistique : <b>A un tour donné, quelle est la probablilité qu'un pilote réalise un arrêt au stand ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut remarquer ici que seuls 4% des labels représentent un arrêt au stand : les données ne sont pas du tout équitablement réparties !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(my_dataset['pit'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée les ensembles d'entraînement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On tente de prédire avec une seule feature mais qui est la combinaison de plusieurs autres\n",
    "cleaned_df = my_dataset[['lapDelta','pit']]\n",
    "\n",
    "#On retire les valeurs nulles\n",
    "cleaned_df = cleaned_df.dropna()\n",
    "\n",
    "#On utilise une fonction de sklearn pour créer les ensembles d'entraînement et de test.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "#On extrait les labels et les données\n",
    "train_labels = np.array(train_df.pop('pit'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('pit'))\n",
    "test_labels = np.array(test_df.pop('pit'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "#On sépare le dataset pour pouvoir affecter des poids de classe : ceci est important pour contrebalancer\n",
    "#le fait que les classes sont inéquitablement réparties\n",
    "\"\"\"ATTENTION : PAS ENCORE IMPLEMENTE DANS L'ALGORITHME DE REGRESSION\"\"\"\n",
    "pit_y = cleaned_df[cleaned_df['pit'] == 1]\n",
    "pit_n = cleaned_df[cleaned_df['pit'] == 0]\n",
    "neg = pit_n[\"pit\"].count()\n",
    "pos = pit_y['pit'].count()\n",
    "total = neg+pos\n",
    "display(pit_y.describe())\n",
    "display(pit_n.describe())\n",
    "#On divise par 2 pour garder la perte dans le même ordre de grandeur\n",
    "weight_for_0 = (1.0 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1.0 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from logistic import LogisticClassifier\n",
    "classifier = LogisticClassifier()\n",
    "model = classifier.fit(train_features.T, train_labels,num_iterations = 2000, learning_rate = 0.05, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère l'historique des coûts\n",
    "costH = model['costs']\n",
    "#On récupère les prédictions\n",
    "predictions = classifier.predict(test_features.T)\n",
    "test_labels = np.transpose(test_labels)\n",
    "# print(predictions.tolist())\n",
    "print(np.sum(predictions))\n",
    "print(test_labels.shape)\n",
    "print(predictions[predictions>0.2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(costH))\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax3 = fig.add_subplot(111)\n",
    "l1, = ax3.plot(np.arange(len(costH)), costH, 'red')\n",
    "plt.suptitle('Evolution de la RMSE en fonction des iterations')\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche la matrice de confusion\n",
    "\n",
    "**TODO : Coder la matrice à la main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Vrai label')\n",
    "    plt.xlabel('Label predit')\n",
    "\n",
    "plot_cm(test_labels[0], predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
